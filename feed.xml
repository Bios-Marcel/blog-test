<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Marcel Schramm</title>
    <link>https://marcelschr.me/blog-test</link>
    <description>thoughts on random topics, but mostly tech</description>
    <managingEditor>marcelschr@protonmail.com (Marcel Schramm)</managingEditor>
    <pubDate>Sun, 27 May 2018 00:00:00 +0000</pubDate>
    <item>
      <title>Go lacks enums</title>
      <link>https:/marcelschr.me/blog-test/articles/go-lacks-enums.html</link>
      <description>thoughts on random topics, but mostly tech</description>
      <content:encoded><![CDATA[<p>As a Java programmer, I heavily make use of enums.
The reason is quite simple. Whenever I have a fixed set of values, i can easy
iterate over them and switch over them. The reason why I really like switching
over enums though, is that I am using an IDE that notifies me of every switch
that doesn't handle all possible values of an enum. Let's say I had the
following code:</p>

<code><pre>
public enum CarManufacturers {
  FIAT,
  FORD,
  MERCEDES,
  OPEN;
}

void someFunction(CarManufacturer manufacturer) {
  switch (manufacturer) {
    case FIAT:
      //SOMETHING
  }
}
</pre></code>

<p>I would get an error stating that a switchcase I had wasn't handling all
possible values and doesn't have a <code>default</code> case either. For those
who don't know, the <code>default</code> case is basically a catch-all case
for that can be used as a last resort. While switch-cases over enums are
technically not exhaustive in Java, probably because of being able to
technically extend an enum via reflection, the IDE still treats it that way.
If you extend an enum at runtime you deserve to burn either way.</p>

<p>So, the value that this provides to me, is that I can extend an enum and be
notified of all code pieces that need work.</p>

<p>Now let's look at Golang. In Go we don't have enums. The idiomatic go way for
such things appear to be type aliases and the <code>iota</code> keyword.</p>

<p>For example:</p>

<code><pre>
type CarManufacturer int

const (
    Fiat = iota
    Ford
    Mercedes
    Opel
)

var Gotcha CarManufacturer = 5

func someFunction(x CarManufacturer) {
    switch x {
    case Fiat:
    case Ford:
    case Mercedes:
    case Opel:
    }
}
</pre></code>

<p>This creates the constants <code>Fiat</code> to <code>Opel</code>, incrementing
their value by one starting from <code>0</code>. However, as you can see, I can
manually create another value with the same type. The problem is, that anyone can
basically do this. So you never know whether you get some weird and unexpected
values at runtime. While you can still handle those with a <code>default</code>
case, my problem here really is the lack of static analysis and warnings. As the
compiler basically can't know whether you've handled all cases.</p>]]></content:encoded>
      <pubDate>Sun, 20 Sep 2020 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Java RMI - Better error handling and performance with lambdas</title>
      <link>https:/marcelschr.me/blog-test/articles/java-rmi-better-rmi.html</link>
      <description>thoughts on random topics, but mostly tech</description>
      <content:encoded><![CDATA[<p>Even though Java RMI is already very old and has some problems, there are
still a lot of application that use it. While some applications have no
time, money or resources to migrate away from RMI, others might not be able to
migrate away, due to the fact that the RMI-Stubs they consume are external
services or whatever.</p>

<p>In the product that I work on, we use quite a big RMI-API in order to do
synchronous communication between client and server. Our structure is however
not optimal. Services are split into topics, such as <code>Project</code> or
<code>User</code>. Each Service has a server-side interface and a client-side
implementation of that interface that catches <code>RemoteException</code>s.
Sadly all our try-catch constructs pretty much look like this:</p>

<code><pre>
try {
  Service.lookup(Service.class).method(parameters);
} catch( RemoteException exception ) {
  logger.error("Ooopsie woopsie!!!11!!");
  return null;
}
</pre></code>

<p>So ... not very useful. The problem with this is, that we can't really
handle any errors that occur during the actual method-call, such as
<code>ConnectException</code>. Well, it could, but it'd require tons of
boilerplate for every method that you ever want to be able to call. As it
is now however, the call would silently fail and return and incorrect return
value which we can't differentiate from a correct return value.</p>

<p>However, we do handle errors that occur during the lookup of the RMI-stub. But
technically another error could occur between retrieving the stub and calling
the method on it.</p>

<p>Another problem with this approach is, that looking up the stub is actually a
network call as well, meaning each RMI-call has at least doubled latency,
ultimately dragging down the performance by a lot.</p>

<p>Finally the most annoying part about the solution, was that we had to write
these boilerplate methods to be able to use the RMI-methods at all.</p>

<p>However, behold the lambdas!</p>

<p>Using lambdas we can easily do both the error handling, the call-retrying
and won't have to write as much boilerpalte. While lambdas clearly take a
bit more memory, I think it's worth the lower pressure on the network.</p>

<p>The interface is rather simple. We have two methods, one for calling methods
that don't return a value and one for the ones that do. For the sake of keeping
this post a bit smaller, I've simplified it a lot:</p>

<code><pre>
public static synchronized <ServiceType extends Remote, ResultType> ResultType get(
  final Class<ServiceType> serviceClass,
  final ServiceResultFunction<ServiceType, ResultType> methodcall,
  final int amountOfRetries)
{
  try {
    ServiceType service = lookupServiceOrGetFromCache(serviceClass);
    return methodcall;
  } catch ( ConnectException exception ) {
    //Clearly the code doesn't make sense like this, but you get the gist.
    if (amountOfRetries == 0) {
      throw new ConnectionFailedException(...);
    }
    get(serviceClass, methodcall, amountOfRetries-1);
  } catch ( RemoteExcception exception ) {
    //Business Exception
    throw new RuntimeException(exception);
  }
}

public static synchronized <ServiceType extends Remote, ResultType> ResultType get(
  final Class<ServiceType> serviceClass,
  final ServiceResultFunction<ServiceType, ResultType> methodcall.
  final int amountOfRetries )
{
  ...
}
</pre></code>

<p>Now you can call any of your RMI-stub-methods without having to write additional
boilerplate:</p>

<code><pre>
User user = Services.get(UserService.class, userService -> userService.findByID(4));
System.out.println(user.getRegisteredDate());
</pre></code>

<p>I hope this will help someone in the future ;)</p>]]></content:encoded>
      <pubDate>Fri, 19 Jun 2020 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Don&#39;t be sorry</title>
      <link>https:/marcelschr.me/blog-test/articles/dont-be-sorry copy.html</link>
      <description>thoughts on random topics, but mostly tech</description>
      <content:encoded><![CDATA[<p>Something I have noticed in the open source community
and also in myself specifically, is that people feel guilty for things they
don't do. You haven't answered that issue from a week ago, just because you
didn't feel like it? You forgot fixing that terrible bug in that library you
started making for fun, but others started relying on? You don't feel like
keeping to work on a certain thing anymore or heavily slow down the pace?
Don't feel sorry! You are doing all of this in your free time. YOUR free
time.</p>

<p>Users of software, whether it's end-user applications, libraries or
whatever, will always have expectations. However, YOU don't have to meet
these. You haven't signed a contract, youaren't being paid and you probably
haven't promised anyone anything.</p>

<p>While I want to believe all of this myself, I find it to be very hard.
However, feeling bad won't help me or anyone else for that matter.</p>]]></content:encoded>
      <pubDate>Sat, 14 Dec 2019 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>git reset --hard isn&#39;t that hard</title>
      <link>https:/marcelschr.me/blog-test/articles/git-reset-hard-is-not-so-hard.html</link>
      <description>thoughts on random topics, but mostly tech</description>
      <content:encoded><![CDATA[<p>Like the experienced git user that I am, I accidentally deleted some of my
code. I did this by running <code>git reset --hard HEAD^^</code>. I meant to only insert
one circumflex, but that key acts differently on windows than it does on linux.
Sadly I am already way too used to the linux behaviour, which only inserts one
circumflex after hitting the key twice.</p>

<p>After a short search on StackOverflow, I found out, that reset doesn't
actually drop a commit. Instead the branch will just stop tracking that
commit. Meaning that you can still access the commit, as long as you still
have the commit-hash or you can try finding it with </code>git reflog<code>.</p>

<p>After reading the man-page for <code>git reset</code> this also makes sense, since all
that <code>git reset</code> is doing, is to modify the index and optionally your working
tree.</p>

<p>However, this is even more interesting, when you are deleting a branch. A
branch is really nothing more than a chain of tracked commits. So even after
deleting a branch, you can still find the commits in the reflog. And simply
<code>git cherry-pick</code> whatever you need.</p>]]></content:encoded>
      <pubDate>Fri, 29 Nov 2019 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Installing Fedora 31 on a Macbook Pro 2014</title>
      <link>https:/marcelschr.me/blog-test/articles/installing-fedora-on-mbp.html</link>
      <description>thoughts on random topics, but mostly tech</description>
      <content:encoded><![CDATA[<p>The last time I decided to install something else than
Mac OS on my Macbook, I decided to install an arch-based distribution. My
choice was Antergos, since it was basically an easy installation of arch, but
without additional software and all the good stuff, I guess. For my DE I
decided to use i3, which was a pre-installation option at Antergos.
However, the whole thing was somewhat painful, as there were a couple of
unfunctional-by-default things:</p>
<ul>
<li>Backlight (Changing / Restoring)</li>
<li>Brightness (Changing / Restoring)</li>
<li>Wi-Fi (Even after installing the driver, I still had connection issues)</li>
<li>Bluetooth (Even after getting the driver, it was horrible)</li>
<li>No system-wide scaling</li>
<li>No thermal management</li>
</ul>

<p>While all of that was kind of annoying, it was somewhat manageable, but stuff
like the brightness changing at some point even broke during an update.</p>

<p><em>Now, behold Fedora!</em></p>

<p>Fedora 31 comes with Gnome 3.34+ which has recently seen a lot of improvements.
Out of the box, everything except for the Wi-Fi just worked. Getting the
proprietary Broadcom 4360 driver needed to be done via a custom package.
Besdides that, the only other thing I had to change was the fn-mode key, which
I swapped from <code>1</code> (always pressed) to <code>2</code> (Never pressed).
Two of the FN-Keys are dead, but I don't even know what they were for. Dead
meaning that they are just not bound to any function by default.</p>

<p>Besides those two little itches, there were three other welcome suprises. Those
being that the scrolling direcrion was "correct" by default (the Mac way) and
the screen brightness automatically adjusts according to the light sensor. The
best of those three, was probably the fact that scaling just worked out of the
box. Both the Gnome UI and application all seemed to scale correctly. In the
past, this was, in my opinion, one the major weaknesses on the Linux desktop.</p>

<p>Oh and sadly, the Bluetooth had stutters as well. This was due to interferences
with 2.4Ghz Wi-Fi and could be temporarily fixed by swapping over to 5Ghz.
This issue might be fixable by changing some settings, but I don't care for
now, as I don't really use Bluetooth.</p>

<p>The only other nice to have thing so far, would be the nice touchpad gestures
that you get by default in Mac OS. Especially the basic ones like pinch to zoom
were really pleasant to use.</p>

<p>So far, it seems like Fedora will be the daily driver for my MBP.</p>]]></content:encoded>
      <pubDate>Sun, 17 Nov 2019 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Don&#39;t refork a GitHub repository every time you want to contribute</title>
      <link>https:/marcelschr.me/blog-test/articles/do-not-refork-a-project-every-time-you-contribute.html</link>
      <description>thoughts on random topics, but mostly tech</description>
      <content:encoded><![CDATA[<p>Sometimes people contribute to one of my
projects, and every time that they want to contribute, they delete
their fork and fork the project again.</p>

<p>They usually do this because they don't know how to easily get an up-to-date
master branch again. Since it's much easier to just hit "delete" and "fork"
again, that's what they do instead.</p>

<p>However, this problem usually occurs when people start working on the `master`
branch instead of a branch specifically made for their PR.</p>

<p>So the next time you want to work on a fork of some project with the intent to
contribute your changes via a PR, do the following instead:</p>

<code><pre>
# Clone your fork
git clone git@github.com:/you/project
# Add the original repository as a new remote
git remote add original https://github.com/someone/project
# Now you'll have the remotes "origin" (fork) and "original" (original)
# We assume that your current master branch has no exclusive changes
# Now update your master using the originals masters state
git pull original master
# Now that you have an up-to-date master, create a new branch of that
git checkout -b your_new_feature
# This creates a new branch called `your_new_feature` and checks it out
# Now start implementing your feature and commit the changes.
# When you are done, push your changes to the fork
git push --all origin
# --all will push all branches to the remote
# Now create your PR via GitHub. As soon as it gets accepted into
# master, you can repeat the same procedure starting at
# `git pull original master`
</pre></code>

<p>This way you won't have to worry about both remotes having different
commits, merge commits or whatever, since all your changes happen on a
throwaway branch anyway.</p>

<p>In case you already have a poluted <code>master</code> branch, you
can do the following:</p>

<code><pre>
# Check the originals master out
git checkout original/master
# This will bring you into a "Detached HEAD" state, meaning you aren't on a
# branch, but on a specific commit you could say.
# Now delete master locally
git branch -D master
# After deleting master, we use our current state to recreate it
git checkout -b master
# Now we'll locally have an up-to-date master
# Now we push, but we need to apply `--force`, since our commit will delete commits that already exist upstream.
git push --force
</pre></code>

<p>I hope this helps ;)</p>

<p>If you have an easier way of doing those things, leave a comment!</p>]]></content:encoded>
      <pubDate>Sun, 14 Jul 2019 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>UX on websites</title>
      <link>https:/marcelschr.me/blog-test/articles/ux-on-websites.html</link>
      <description>thoughts on random topics, but mostly tech</description>
      <content:encoded><![CDATA[<p>Rant time!</p>

<p>So, today I wanted to use <a href="https://issuehunt.io">IssueHunt</a>.
The website allows developers to post tasks and everyone can back the task
up with money. So that whoever solves the tasks, gets paid by the backers.
If you are someone who wants to solve one of those tasks, you have to search
for one that suites you. The site allows searching through the tasks with a
paginated list and a component on the left side of the website where you
can select your target languages.

<img src="https://raw.githubusercontent.com/bios-marcel/Bios-Marcel.github.io/master/images/uxonwebsites/thepage.png" loading="lazy" alt="Screenshot of the website"/>

<p>This is what the site looks like. The width of my browser window is <em>960px</em>
and is used as follows:</p>
<ul>
<li><em>128px</em> (13,3%) - Whitespace on the left</li>
<li><em>160px</em> (16,6%) - the filter component</li>
<li><em>30px</em> (3,1%) - whitespace</li>
<li><em>510px</em> (53,1%) - the actual content</li>
<li><em>128px</em> (13,3%) - Whitespace on the right</li>
</ul>

<b>Not all numbers might add up to the full 100%, but you get the point.</b>

<p>So about half of the website is content, the rest is mostly whitespace and
the filter component. The filter component doesn't even use the height of the
site well. It would've been much better at the top, so the full width could be
used for the content. This is fine for a fullscreen window, but not for small
windows. Oh by the way, responsive design doesn't mean "scales down", it means
to accordingly adapt the application depending on your current display size
and device.</p>

<p>If you wonder why I'd use such a small browser window, that's becuase I was
watching some stuff on YouTube while browsing IssueHunt. And no, I don't
want to only do one thing at the same time.</p>

<p>Okay, next is he filtering component. It lists languages that you can
click to select them. It is basically like a list of checkboxes ... unless you
click the first item called <code>All languages</code>, because that will
deselect all the items below. Since there are many many technologies, not all
of the available items are in that list. There is a secondary mcomponent, that
shows the rest of the languages and allows you to search through them. Just
like the list above, you can select multiple items. Every time you select an
item, the whole site will refresh. Since there is no button to apply the new
filter options, this makes sense. However ... an apply button would have made
more sense.</p>

<p>Oh and the filtering would display any task that fits one of your selected
items, which wasn't obvious, since the UI indicated that in no way.</p>

<p>There are other ways to get the same functionallity, but less horrible. Look
at stack overflow for example. If you want to chose your tags, you get a
textfield where you can enter a word and it will show you all available options
that contain the word you have entered and it will even display a little piece
of explanation. If you want to delete one of the tags, you just hit the
<code>X</code> on one of the tags. The component barely takes any space and does
exactly what it should do.</p>

<p>So far so bad. Now I wanted to look at the actual content, first I looked at
the available issues for JavaScript, just to see how many there are. Right
below the list is a pagination component:</p>

<img src="https://raw.githubusercontent.com/bios-marcel/Bios-Marcel.github.io/master/images/uxonwebsites/pagination_currently.png" loading="lazy" alt="pagination component"/>

<p>It uses <em>180px</em> of the screens width, no matter what the width of
your window is. You got two buttons, one for left and one for right. At
first I thought, that those mean backwards and forward. However, they didn't.
You could've just written <code>first</code> and <code>last</code> on them ...

<p>Okay, since the component only displays 3 items, you have no clue how many
pages there are, even though there was enough space to display more or even
display the first page, the last page and the current range where you are.</p>

<p>After chosing another language than JavaScript, it displayed the same things
again, a <code>1</code>, a <code>2</code> and <code>...</code>. However, after
chosing the second page, the three dots became a <code>3</code>. Very confusing
as well. You could have just shown me three items for three pages.</p>

<p>Now this is what the component should've looked like if there were more items,
than the page could actually fit:</p>

<img src="https://raw.githubusercontent.com/bios-marcel/Bios-Marcel.github.io/master/images/uxonwebsites/pagination_dream.png" loading="lazy" alt="The dream I have"/>

<p>With this you'd be able to:</p>

<ul>
<li>See on what page you are right now</li>
<li>See and visit the first page</li>
<li>See and visit the last page</li>
<li>visit the previous and next page</li>
<li>See what page you are currently on</li>
</ul>

<p>Obviously it should always use as much space as possible, in order to show as
much content as possible. You could theoretically even allow to jump to a
specific page directly, but that's probably useless, since the pages just
contain random items and there shouldn't be a reason to go to a specific page.</p>

<p>And if we have enough items to fit them onto the page, just display all items
without unneccesarily complicating the component.</p>

<p>So what did we learn? Just because something looks good, that doesn't make it
useful. Next time think about your UX before implementing the UI. And yes, I do
in fact think, that the site looks visually pleasing.</p>]]></content:encoded>
      <pubDate>Sat, 08 Jun 2019 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>About offloading work to the client</title>
      <link>https:/marcelschr.me/blog-test/articles/offloading-work-to-the-client.html</link>
      <description>thoughts on random topics, but mostly tech</description>
      <content:encoded><![CDATA[<p>I have been working on an open source Discord client
for a while, it uses the official REST API and tries to reproduce the
features of the original electron client. When I got to the point where I
could actually chat, one of the first things I tried, was sending emojis.
Well, didn't quite work out. When I entered emoji-sequences like
<code>:cry:</code> or <code>:sunglasses:</code>, all I got back was plaintext.
But why is that, if the original client converts all those sequences into
actual Unicode characters? This is simply due to the fact, that in order to
implement this feature, Discord uses client-sided business logic. So before
sending the message to the server, for example:</p>

<code><pre>
What a great day :sunglasses:
</pre></code>

<p>It converts the message into this:</p>

<code><pre>
What a great day ðŸ˜Ž
</pre></code>

<p>This feature works on the desktop-client, the web-client and the mobile-client.
However, my client couldn't do it, since the server doesn't do this thing, even
though the behaviour is supposed to be the same across all devices (clients).</p>

<p>There are other scenarios though, where even the official Discord clients
differ in their behaviour. Take a look at the commands that the client suggests
you when you type a <code>/</code>. The desktop-client and the web-client will
show you a list of available commands and allows you to chose one of them.
However, the mobile client does nothing at all, since it doesn't support a
single of those commands. Not even simple ones like <code>/shrug</code>, which
simply inserts a shrugging kaomoji into the message. But hey, who needs
consistency, am I right <code>Â¯\_(ãƒ„)_/Â¯</code>?</p>

<p>So what if the Discord team decides that they want to write an additional
client at some point? Maybe a native desktop client that doesn't use electron.
Well, they'll have to replicate all client-sided behaviour in their new client,
which means additional time consumption and therefore additional cost. On top
of that it increases the margin for error. If you write the same code twice
in different languages, maybe even with different testing and whatnot, you
might end up introducing errors in one version of the code, but not in the
other. On top of that, maintaining the code becomes harder, since changing the
behaviour on the client means having to change it twice.</p>

<p>Most likely they have a reason to not implement such behaviour on the
server-side though. One of the most obvious reasons would be lowering the
workloads on the server and therefore reducing the amount of money needed in
order to run the backend infrastructure. Even though such a simple feature
sounds trivial and like it wouldn't cost much performance, think about how many
active users Discord has that send messages every second. Eventually for a big
service like Discord it might just pay off.</p>

<p>The next time you implement business logic, you might want to ask yourself the
following question:</p>

<blockquote>
Does it technically matter where I implement the behaviour? Iff not, what are
the benefits for each decision and how much weight do those benefits have to
me personally?
</blockquote>

<p>My own approach is usually to avoid writing business logic more than once,
since it usually just introduces more work in the long-run. As it shouldn't be
a problem as long as you don't have scaling problems, whether due to money
restrictions or hardware restrictions.</p>]]></content:encoded>
      <pubDate>Mon, 13 May 2019 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>VPNs and the lies you are being fed</title>
      <link>https:/marcelschr.me/blog-test/articles/vpns-and-the-lies-you-are-being-fed.html</link>
      <description>thoughts on random topics, but mostly tech</description>
      <content:encoded><![CDATA[<p>Today I'd like to talk about VPNs, despite
the fact that many people have probably already told you the same
thing that I am about to tell you.</p>

<p>So, I have noticed that recently a lot of YouTubers are advertising VPN
services. Those are usually PIA or NordVPN. The promise usually made in
those advertisements, is something along the lines of <em>&quot;Privacy due to full
encryption of your traffic&quot;</em>. Now that sure sounds great, right? Err ... not
really. While encryption would prevent someone from reading or manipulating
your data, you can't simply End-To-End encrypt any traffic.</p>

<p>Usually when you make a requet over the internet, you (the host) create your
request and target some other machine (the server), that lies somewhere else.
Since you are not directly connected to the server (in the same local area
network), your request has to be routed over the internet, meaning it will
hop from device to device, trying to find the most efficient route to your
requests target.</p>

<p>So yes, theoretically you could now encrypt this request before sending it, but
your target server would not understand your encrypted request, since it has no
clue about how to decrypt it. So what a VPN means when it claims that it
encrypts your traffic, is that the route to the VPN (your man in the middle),
will be fully encrypted. As soon as your VPN has proxied your request to your
actual target, your traffic will look the same as it did before encrypting it.
This doesn't mean that unless you use a VPN your traffic is always unencrypted.
As long as your requests uses some protocol that has encryption built-in, your
data will still be encrypted til it reaches the requests target.</p>

<p>So, what does this mean in the end? It means you don't really achieve privacy
just by using some VPN service.</p>

<p>Some people actually get a VPN in order to hide their malicious activies from
third parties that could potentially track them down. Does that at least make
sense? Yes, kinda. The original location of the request will not be known to
a third party. However, they can still ask your VPN who you are or where you
are. And I doubt you really want to trust some random company that promises
you full privacy for just <em>2.99â‚¬</em> a month. However, using the VPN to access
some service that has geographical restrictions or get around blockades that
your government has put up, a VPN is still fine. Even though a simple proxy
would probably do the job, unless your government does deep packet inspection.</p>

<p>Let's not get started talking about free VPN services, like the one that
facebook offered (or still does?). They obviously don't do this because they
want to keep everyone from reading your precious traffic.</p>

<p>Anyway ... back to the YouTubers! It's a shame that strong social media
presences advocate for something they don't seem to understand much about. If
they'd really care about their audiences, they should not advertise such
services or at least inform themselves a bit before doing so. In order to
prevent such false advertisements.</p>

<p><b>EDIT:<b></p>

<p>Someone has pointed out to me that those YouTubers are being paid for making
those advertisements in their videos. I was well aware of that when writing
the post, however, I didn't feel like this would be worth mentioning, because
even if you are paid for something, that doesn't mean you should lie, not inform
yourself or abandon all your values.</p>]]></content:encoded>
      <pubDate>Sat, 11 May 2019 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Be careful when moving files within a git repository</title>
      <link>https:/marcelschr.me/blog-test/articles/careful-moving-files-in-git-repositories copy.html</link>
      <description>thoughts on random topics, but mostly tech</description>
      <content:encoded><![CDATA[<p>So, today I learned something interesting about git that I have been doing
wrong way too often without even noticing it.</p>

<p>Imagine the following scenario:</p>

<p>
You have a file called <code>hello.go</code>, it greets the user with the very simple and
static sentence <code>Hello user.</code>. At this point and time the commit history for
the file looks like this:</p>

<code><pre>
~/code/hello (master)$ git log --follow hello.go
commit 03c325f415ca2418fa9bf9f759ca1fc16f50c8e6 (HEAD -> master)
Author: Marcel Schramm <marceloschr@googlemail.com>
Date:   Fri Apr 19 19:11:06 2019 +0200

    Add initial implementation that simply greets the user with a static sentence.
</pre></code>

<p>Next you decide that a static greeting is quite boring and unpersonal. So you
now have new requirements. The application should greet the user differently
depending on the current daytime. The greeting it uses between 6am and 11am
should be <code>Good morning user.</code>. Starting at 12am til 5pm it should use
<code>Hello user.</code> and starting 6pm it should use <code>Good evening user.</code>.
On top of that it should be able to take the users name via a parameter that can be
passed on startup. So you rewrite your code accordingly.</p>

<p>Now you decide that a more fitting name for this file would be <code>greeter.go</code>,
since it doesn't simply say <code>Hello user.</code> anymore, so you rename it:</p>

<code><pre>
~/code/hello (master)$ git mv hello.go greeter.go
</pre></code>

<p>Your changes were made and your file has been renamed. Now you wanna commit
this, so you add your new file to the staging area:</p>

<pre><code>
~/code/hello (master *+)$ git add greeter.go
</pre></code>

<p>Finally you commit:</p>

<code><pre>
~/code/hello (master +)$ git commit -m "Rename hello.go to greeter.go, since it is more fitting. Change output depending on the daytime and optionally accept a username."
[master d003cc6] Rename hello.go to greeter.go, since it is more fitting. Change output depending on the daytime and optionally accept a username.
 2 files changed, 1 insertion(+), 1 deletion(-)
 create mode 100644 greeter.go
 delete mode 100644 hello.go
</pre></code>

<p>Fine, you are good to move on! Next day you wanna see the history, so you call
git log on your <code>greeter.go</code> file:</p>

<code><pre>
~/code/hello (master)$ git log --follow greeter.go
 commit 33a3c028ef060c600164f0f7c7757012426f319c (HEAD -> master)
 Author: Marcel Schramm <marceloschr@googlemail.com>
 Date:   Fri Apr 19 19:29:26 2019 +0200
 
     Rename hello.go to greeter.go, since it is more fitting. Change output depending on the daytime and optionally accept a username.
</pre></code>

<p>Since, there wasn't enough similarity between the old file and the new file,
git didn't really notice that this is still the same file, but with different
contents. Since <code>git mv</code> is basically just an alias for
<code>git rm</code> and <code>git add</code>. So if you only were to do small
changes, this might work fine. Anyway, you will still have all changes in your
full repository history.</p>

<p>In order to prevent this loss of file history you simply have to first commit
the rename of the file and then do your changes. Never do renaming and changing
of the content in one commit.</p>]]></content:encoded>
      <pubDate>Fri, 19 Apr 2019 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>But we have full test coverage</title>
      <link>https:/marcelschr.me/blog-test/articles/but-we-have-full-test-coverage.html</link>
      <description>thoughts on random topics, but mostly tech</description>
      <content:encoded><![CDATA[<p>I often see people claiming that their tests are as good as they could
get, since they have full (100%) test coverage. And obviously 100% coverage
is as good as it could possibly get. Or is it not? You guessed it, coverage
isn't everything, The quality of the tests plays a big role as well.</p>

<p>Here is a little example of full test coverage that isn't very useful:</p>

<code><pre>
package testme

var (
    someMapping = map[int]string(
        1: "Hello",
        2: "World"
    )

    OutOfBoundsError = errors.New("Out of bounds")
)

func Something(input int) (output string, err error) {
    if input > 0 {
        return someMapping[input], nil
    }

    return "", OutOfBoundsError
}
</pre></code>


<code><pre>
package testme_test

func TestSomething(t *testing.T) {
    result, err := Something(1)
    if err != nil {
        t.Error("result should've been 'Hello', but an error was returned")
    }

    if result != "Hello" {
        t.Errorf("result should've been 'Hello', but was '%s'", result)
    }

    result, err = Something(2)
    if err != nil {
        t.Error("result should've been 'World', but an error was returned")
    }

    if result != "World" {
        t.Errorf("result should've been 'World', but was '%s'", result)
    }

    result, err = Somethng(0)
    if err != nil {
        t.Error("call should've returned an error, but it didn't")
    }
}
</pre></code>

<p>This code will test all statements, meaning that it will have full coverage.
But it won't test all theoretically possible cases. When calling <code>Something</code>
with <code>3</code>, we will get an empty string instead of the expected error, since
accessing a non-existent key in a map will return the types default value.</p>

<p>If you wanna test this out for yourself, go ahead and run this:</p>

<code><pre>
package main

import "fmt"

func main() {
    wow := map[int]int{2: 4}
    fmt.Println(wow[1])
}
</pre></code>

<p>So whenever you write a test, don't look at the code coverage first, instead
pay attention to whether you have tested all possible cases. However, if a
function doesn't have full coverage, that is probably an indicator for cases
that aren't handled or even <abbr title="code that can never be called, no matter what happens">useless code</abbr>.</p>]]></content:encoded>
      <pubDate>Wed, 27 Mar 2019 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>What do I think about Go</title>
      <link>https:/marcelschr.me/blog-test/articles/what-do-i-think-about-go.html</link>
      <description>thoughts on random topics, but mostly tech</description>
      <content:encoded><![CDATA[<p>I have been doing Go for a while now and so far I have enjoyed it. Why do I
enjoy it though? First, let's look at my past!</p>

<p>I have been doing Java for three years now and I can't say that I am happy
with it any more. In the beginning I really liked Java, but over time that
has changed.</p>

<p>Here is a list of stuff that annoys me:</p>

<ul>
<li>Long start-up times</li>
<li>You actually need to have Java on your machine (or ship a JVM)</li>
<li>The JVM nags on your ram</li>
<li><code>NullPointerException</code>s everywhere</li>
<li>It's verbose</li>
<li>For every primitive an object type exists</li>
<li>more...</li>
</ul>

<p>The next language I looked at was Kotlin. Oh boy, Kotlin is so fun! It has
tons of cool features. After a while I stopped using Kotlin as well though,
since it still runs on the JVM and has it's own problems.</p>

<p>I still keep an eye on
<a href="https://github.com/JetBrains/kotlin-native/">Kotlin native</a> though.</p>

<p>Then someone kept shilling Go. After a while, I thought I should just give
it a look. When I started getting into Go, I have noticed a few things that
I really liked. It was very easy to get started. There is an interactive
online tutorial that teaches you the basics and afterwards you just download
Go and get started. You don't have to get a build-tool, you don't have to get a
dependency manager and you don't have to get a test framework or something like
that. Go comes with all those tools built-in, which is what makes it really fun
and easy to get started.</p>

<p>Besides having all those tools built-in, it is also super easy to learn the
language itself, since it doesn't really have many features and a rather
simple syntax. You don't even have to think about formatting and such, as you
won't even be able to compile if the compiler doesn't like the way your code
is formatted.</p>

<p>Overall the language has a nice ecosystem, including it's community, just like
in Java, you'll almost always find an answer to your questions.</p>

<p>I don't think I like Go because it is such a revolutionary and good language.
I think I just like it because it is so easy to get started without any
frustration whatsoever.</p>

<p>However, I am not saying that Go is perfect, just like Java and Kotlin, Go has
it's own problems.</p>

<p>Here are some things I dislike about Go so far:</p>

<ul>
<li><code>nil</code>, which means there are also <code>nil</code> dereferencing errors</li>
<li>No generics (Those would be super handy)</li>
<li>No really good IDE yet (VS Code / Goland come closest to an okay experience)</li>
</ul>

<p>But who knows, maybe I'll start disliking Go as soon as I start any bigger
projects, which means that I'll probably face bigger problems.</p>]]></content:encoded>
      <pubDate>Thu, 13 Dec 2018 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Think Twice Before Using Varargs</title>
      <link>https:/marcelschr.me/blog-test/articles/think-twice-before-using-varargs.html</link>
      <description>thoughts on random topics, but mostly tech</description>
      <content:encoded><![CDATA[<p>Varargs, which is short for
<a href="https://en.wikipedia.org/wiki/Variadic_function">variadic arguments</a>,
are a pretty cool thing. They allow your functions to take from 0 to n
arguments, the amount of possible function arguments might differ from
language to language though. Most of you have probably already used a
function which makes use of varargs. Throughout this blog post, I am gonna
use Java for examples.</p>

<p>As an example, let's look at <a href="https://docs.oracle.com/javase/7/docs/api/java/lang/String.html#format(java.lang.String,%20java.lang.Object...">String.format(String, Object...)</a>:</p>

<code><pre>
String name = "Marcel"
String.format("Hello %s.%nThe weather is quite good today.", name);
</pre></code>

<p>The resulting String would look like this:</p>

<samp><pre>
Hello Marcel.
The weather is quite good today.
</pre></samp>

<p>We could also use the function to just add a line break, but pass no additional
variables:</p>

<code><pre>
String name = "Marcel"
String.format("Hello.%nThe weather is quite good today.");
</pre></code>

<p>This would still compile, since varargs allow from 0 to n arguments, which
is totally fine for our use case though.</p>

<p>But let's look at a more dangerous example:</p>

<code><pre>
class Screamer {
    /**
     * Screams each passed word onto a new line.
     *
     * @params words are the things to be screamed
     */
    void screamWords(String... words) {
        for( String word: words ) {
            System.out.println("Scream: " + words.toUpperCase());
        }
    }
}

class IntenseScreamer extends Screamer{
    @Override
    void screamWords(String... words) {
        //Intensify the words by adding exclamation marks!
        for( int index = 0; index &lt; words.length; index++ ) {
            words[index] = words[index] + "!!!";
        }

        super.screamWords();
    }
}
</pre></code>

<p>In case you haven't noticed the error, I forgot passing the words to the
supercall. That happens quite easy, since it allows 0 arguments as well.
In such case, an empty array will be passed, since varargs are nothing but
arrays under the hood.</p>

<p>I am not telling you to avoid varargs completely, but sometimes you might just
want to use an array, as it will give you some compile-time safety, since you
have to at least pass an empty array.</p>

<p>In my opinion, you should avoid using varargs if you could potentially pass
an incorrect amount of values, since there can not be any compile-time checking
without using third party tools.</p>

<p>This actually happened to me at work, which is why I bring it up. I wasted a
while before I found the problem, since I didn't check every place where the
parameters were passed on. I just knew that nobody mutates them and I knew
that they were passed correctly in the beginning, so why the hell was I
getting an empty array.</p>

<b>EDIT:</b>

<p>A colleague pointed out that it might annoy some people to always create arrays,
which is kind of the reason why varargs are so nice to use. A possible solution
to that problem would be a mandatory parameter followed by a vararg parameter of
the same type.</p>

<p>Here is an example:</p>

<code><pre>
//Defining your method
void hello(String nameOne, String... restOfNames) {
    String names[] = new String[restOfNames.length + 1];
    names[0] = nameOne;
    System.arraycopy(restOfNames, 0, names, 1, restOfNames.length);

    //Implementation...
}

//Calling it
hello("Marcel", "Jeff", "John");
</pre></code>

As you can see, this requires some additional logic, but it would usage wise be
the same for the methodcaller, unless the intention was to actually pass a
complete array, in that case the caller would have to create a new smaller array
and pass the first cell of the old array as the first parameter. This would also
be worse performance wise, even though this would usually not be critical.]]></content:encoded>
      <pubDate>Tue, 11 Dec 2018 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Why do people expect software to be for free?</title>
      <link>https:/marcelschr.me/blog-test/articles/why-do-people-expect-software-to-be-for-free.html</link>
      <description>thoughts on random topics, but mostly tech</description>
      <content:encoded><![CDATA[<p>
Recently I have been wondering why everyone seems to expect software
to be free. Free software has existed for quite a while, but
many people have started to expect software to be free by default.
</p>

<p>
I assume that many people think that the software they use
in their daily life is already free. Let's take Facebook as an example.
Do you think Facebook is free? Yes, it is free to use, however, this doesn't
mean that you aren't paying in a way. When using Facebook you are paying
with your personal data and you are probably seeing ads, unless you are
using an ad-blocker. By the way, even some ad-blockers aren't completely
free, some actually mine data or only block ads that they aren't paid for.
The same goes for other free-to-use software that you use.
</p>

<p>
<em>
In case you are interested in using an ad-blocker, I suggest you take
at look at <a href="https://github.com/gorhill/uBlock)">UBlock Origin</a>.
</em>
</p>

<p>
Okay, so what do we pay for? We pay for games, right? Buying a AAA game
for 60â‚¬ still seems to be accepted by most gamers. However, would they buy
a 5â‚¬ game for their smartphone? Unlikely. I have noticed that many people
seem to expect smartphone apps to be free (subsidized by ads) or extremly
cheap. Why do many people deem 5â‚¬ for a smartphone application to be much?
I assume this is due to the fact that smartphone apps feel
more like a "side thing" that you just use in order to keep the boredom away.
There are also apps that don't focus on entertainment. As far as I know,
those kind of apps are less used by the average smartphone user though.
</p>

<p>
Do I pay for mobile applications? No, not really, the only app I have ever bought
was Teamspeak 3 and I refunded it, since it was terrible. However, I do not like
to use applications that are subsidized by advertisements, because I believe that
the advertisement model is completely broken. Applications that implement an
advertisement model often decrease in user experience. Either by showing popups,
using up the space on your screen or even adding trash to your devices system.
I generally believe the way that most advertisements are made today, is very
dishonest. Whenever seeing an advertisement on the TV, I feel like I am being
lied to.
</p>

<p>
In order to avoid such subsidation models, I try to use as much truly
<b>free software</b> as possible, also referred to as <b>free open source software</b>.
However, people should be paid for the work they do, right?
</p>

<p>
Yes, everyone should be paid for the work they do, at least I believe so.
So, what can you do?
I suggest you start to try using more free open source software and if you
like what you are getting, drop a donation from time to time, it really helps!
Some software projects are actually completely subsidized by donations, for
example an operating system called <a href="https://elementary.io/de/">Elementary OS</a>.
It has adopted the `pay what you want` model, meaning that if you want to, you
can just not pay anything. The system also has a software store that allows you
to optionally pay for anything that you install via the store. Such principles
are viable and are being used, however, most companies still try to maximize
their outcome by any chance and therefore such things will unlikely ever be
adopted by big companies.
</p>

<p>
Another good payment model is the one that <a href="https://play.euw.leagueoflegends.com/">League of Legends</a> is using.
You can download and play the game for free, however, you can still
purchase ingame items in exchange for real money. Those ingame items
don't provide the player any advantages over the other players, since
they are only visual items. Those items can be skins for characters
or emoticons and ward-skins. League of Legends has been doing it this way
for a long time now and it seems to work just fine.
</p>

<p>
<b>EDIT: Someone just pointed out that you could also buy
champions(playable characters). In the beginning you only have a specific
set of characters. Until season 6 or 7 it was quite hard to get many
characters in a short amount of time. At a certain point they made it
much easier though.</b>
</p>

<p>
So, what's the point of this post? I'd like to encourage you to start paying for
software. I assume just like me, many of you are annoyed by advertisements,
especially looking at mobile aplications and websites. If more people were to
pay for software and media, then less companies would decide to start
build their products around an advertisement model. I am not telling you that
you have to use free open source software
though, that's just my opinion. However, think about paying for what you use,
because just like the machine that you use for reading this post, someone
had to produce that software.
</p>

<p>
Food for thought: Why do you think that no one expects physical goods or
services should be free?    
</p>]]></content:encoded>
      <pubDate>Thu, 15 Nov 2018 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>A Month Into Solus Budgie</title>
      <link>https:/marcelschr.me/blog-test/articles/back-to-linux.html</link>
      <description>thoughts on random topics, but mostly tech</description>
      <content:encoded><![CDATA[<p>A while ago I decided to start abandoning proprietary services, one of those was windows.<p>

<h2>Backstory</h2>

<p>The first Linux I had ever seen and actively used was <q>open SUSE</q> in 2011 I believe, I was about 13 years old at that time.</p>

<p>I was just a "normal" user and solely used it to play games and surf the web.
At some point I stopped using SUSE ... I forgot why, but probably due to me being too stupid to achieve what I wanted to achieve.
I then switched to <q>Windows 7</q> and used it for about 3 to 4 years and then decided to get <a href="https://www.ubuntu.com/">Ubuntu</a>, at that
point and time I had to abandon all the games that I had played on windows.
I missed my games and switched back to windows 7 after about 3 months.
As soon as Windows 10 was available I did the free upgrade and was quite satisfied, since Windows 10 fixed a lot of the quirks that Windows 7 had:</p>

<ul>
<li>Flat Design</li>
<li>Multiple workspaces (desktops)</li>
<li>windows snapping with proper multi monitor support</li>
<li>It was faster</li>
<li>more ... (I am too lazy to list more)</li>
</ul>

<p>on the other hand it introduced some annoying stuff, like <q>builtin advertisements</q> in the startmenu, <q>preinstalled bloatware</q>, <q>annoying popups</q> and <q>additional telemetry</q> that you can't easily disable.
Also they started to replace more and more of old Windows 8.1 and below GUI with their new fluent design GUI ... which to be honest is worse in my opinion. Well ... enough talking about windows.</p>

<h2>Solus</h2>

<p>In the beginning I decided to go with <a href="https://www.opensuse.org/">open SUSE</a> due to the fact that it was the first linux I had ever seen and used. After only 3 days of pain (KDE 5 Plasma constantly crashing) I switched to Solus.</p>

<p>Just like <q>open SUSE</q>, Solus wasn't based on another big distro, like <q>Ubuntu</q> is based on <q>Debian</q>. One downside was, that I can't use any <q>.rpm</q> or <q>.deb</q> packages (at least not by default). On the other hand we have <a href="https://snapcraft.io/">Snap</a> and <a href="https://flatpak.org/">Flatpak</a> nowadays, which provide a way to easily install software across different linux distributions. Most of the software I needed was available in official Solus repositories, those are quite up-to-date, sadly they are lacking some old and common stuff like <q>xterm</q>, simply because <q>there is no need for it</q>.</p>

<p>I really hate waiting, which is why I am happy that Solus starts up quick, logs you in quick and even shuts down lighting fast.</p>

<p>I actually don't use much operating system features, but neither did I use much operating system features when I was on Windows though.
I just need a minimal OS, which is fast, up-to-date and looks good, Solus satisfies all of those needs in my opinion.</p>

<h3>Budgie</h3>

<p>Solus is available with different desktop environments:</p>

<ul>
<li>Gnome</li>
<li>Mate</li>
<li>Budgie</li>
</ul>

<p>I decided to go for Budgie, simply because it looked minimal and well designed. I also wanted to try something new. Overall I like Budgie.</p>

<p>It comes with some <q>Windows 10</q>-like Notification center, called <q>Raven</q> which also integrates media playback:</p>

<img src="/images/solusbudgiepost/mediaplayback.png" loading="lazy" alt="Media playback raven"/>

<p>and easy access to your audio input and output devices:</p>

<img src="/images/solusbudgiepost/audiocontrol.png" loading="lazy" alt="Audio control"/>

<p>It also supports system tray icons by default, unlike Gnome nowadays.</p>

<p>It has an application menu for listing and grouping installed applications, the <q>Budgie Menu</q>, sadly <a href="https://github.com/solus-project/budgie-desktop/issues/1444">i have experienced heavy problems with said component</a>, which is why I deactivated it and use the <q>run command prompt</q> instead. The <q>run command prompt</q> only allows you to type in a name and execute one of the search results. Back on Windows 10 I only ever used the start menu to do exactly that, so I am not missing out on anything here.</p>

<p>Budgie has some Gnome integration and ships with some of the default gnome tools. I am not the biggest friend of the gnome tooling. As I already mentioned I used KDE for a short while, I really loved it, especially the file manager (<q>Dolphin</q>), which had terminal integration and multi pane support and the terminal (<q>Konsole</q>) which supports horizontal and vertical tiling.</p>

<p>Budige comes with <q>Nautilus</q>, which doesn't support the two features I like about <q>Dolphin</q>, so I ended up deleting <q>Nautilus</q> and am now using <q>Caja</q>, which is a fork of the old <q>Nautilus</q> (back when it still had features). I first tried using Dolphin, but sadly it didn't work that well without the KDE desktop.</p>

<p>I removed <q>gnome-terminal</q> and replaced it with <a href="https://github.com/gnunn1/tilix">Tilix</a>. I went for Tilix due to the fact that it supports tabs, horizontal and vertical tiling and easy customization of keybindings.</p>

<h3>Gaming</h3>

<p>Okay, let's talk about the actually important stuff ... playing games!
I bet you all know, that windows is usually the best choice for gaming, sadly I can't deny that fact.</p>

<p>However, Solus allows easy installation of 32-bit and 64-bit NVIDIA drivers, reducing the initial problems a lot. And by using <a href="https://lutris.net/">Lutris</a>, you can easily install a lot of different Windows-only games.</p>

<p>Lutris can manage games for different platforms:</p>

<ul>
<li>wine</li>
<li>native Linux games</li>
<li>Linux Steam</li>
<li>Windows Steam</li>
<li>Browser</li>
<li>and a couple more</li>
</ul>

<p>allowing you to easily manage your game library using a single application.</p>

<p>You could also manually install the native Steam client via wine, but I would suggest using Lutris if possible, as youâ€™d have to do all the dependency management for the games yourself otherwise and probably youâ€™d even have to create two wine prefixes, one for 64-Bit Steam and one for 32-Bit Steam.</p>

<p>Solus allows you to install the native Steam client via <q>eopkg</q>, its integrated package manger, in addition to that, it also offers <a href="https://github.com/solus-project/linux-steam-integration">improved integration for steam</a>.</p>


<p>Back on windows I played a lot of different games:</p>

<ul>
<li>Dark Souls 2</li>
<li>Dark Souls 3</li>
<li>Dishonored 2</li>
<li>Warframe</li>
<li>Heroes of the Storm</li>
<li>Hearthstone</li>
<li>League of Legends</li>
<li>Brawlhalla</li>
<li>Battlerite</li>
<li>CS:GO</li>
<li>Fortnite</li>
<li>Osu!</li>
<li><em>Insert bunch of indie games here</em></li>
</ul>

<p>Except for some of the indie games and CS:GO, those are all non-linux titles.</p>

<p>It is no problem to run low graphics games like, Brawlhalla, League of Legends or Hearthstone via Wine, but games like Dark Souls, Dishonored or Fortnite aren't playable unless you have very powerful hardware.</p>

<p>Even though I have a GTX 1050 TI, I am unable to play Warframe, Dishonored, Heroes of the Storm or Dark Souls via wine.</p>

<p>Currently, those are the Windows-only games that I got up and running (putting native Linux titles aside):</p>

<ul>
<li>League of Legends</li>
<blockquote>I am using the OpenGL version with low graphic settings, since directX9 causes heavy client bugs</blockquote></li>
<li>Brawlhalla
<blockquote>Has lags sometimes, but runs fine most of the time.</blockquote></li>
<li>Battlerite
<blockquote>Runs fine with directX9</blockquote></li>
<li>Hearthstone
<blockquote>Might not run perfect at all times, but it is a card game, so it doesnâ€™t really matter<blockquote></li>
<li>Osu!
<blockquote>Runs fluid and my Tablet (Huion H420) also works. In order to easily add new songs to the song directory, I use the <q>mv</q> command as my default application for <q>.osz</q> files.</blockquote></li>
</ul>

<p>And those are the ones that I didnâ€™t get to work:</p>

<ul>
<li>Heroes of the Storm
<blockquote>This really surprised me, the game had pretty stable fps of 120+, but the fps dropped to <q>0</q> for a moment, as soon as any character used an ability. Since using abilities is what you do the whole time, the game was simply unplayable.</blockquote></li>
<li>Dark Souls 3
<blockquote>I donâ€™t know why, but the game simply didnâ€™t start, I might investigate this further at some point.</blockquote></li>
<li>Fortnite
<blockquote>Since Fortnite uses BattleEye anti-cheat, which doesnâ€™t work with wine, this game canâ€™t be played.<blockquote></li>
<li>Warframe
<blockquote>Well, it works, but only at unstable 40 fps on minimal settings, which is no fun</blockquote></li>
</ul>

<h3>Conclusion</h3>

<p>I can recommend Solus for daily usage. Most people might not be as picky about their file manager and terminal as I am, so that shouldn't be something that most users would have to mess with.</p>

<p>Probably Solus shouldnâ€™t have been my first choice though, since I obviously preferred the tooling that KDE 5 Plasma gave me, but sadly I had already lost trust in it after seeing how buggy it is on open SUSE Tumbleweed and open SUSE Leap. I didnâ€™t feel like wasting my time to give it a third try.</p>

<hr/>

<p>I have probably just scratched the surface of what might be important to some people, sorry for that.</p>

<p>If you find any mistakes, like wrong information or typos, feel free to submit a pull request.</p>]]></content:encoded>
      <pubDate>Sun, 27 May 2018 00:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>